output exec {{
    #define XLEN sizeof(RegVal) * 8

    uint64_t
    SEW(const uint64_t vtype)
    {
        return 8 << bits(vtype, 5, 3);
    }

    /*
    * Encode LMUL to lmul as follows:
    *     LMUL    vlmul    lmul
    *      1       000       0
    *      2       001       1
    *      4       010       2
    *      8       011       3
    *      -       100       -
    *     1/8      101      -3
    *     1/4      110      -2
    *     1/2      111      -1
    *
    * then, we can calculate VLMAX = vlen >> (vsew + 3 - lmul)
    * e.g. vlen = 256 bits, SEW = 16, LMUL = 1/8
    *      => VLMAX = vlen >> (1 + 3 - (-3))
    *               = 256 >> 7
    *               = 2
    * Ref: https://github.com/qemu/qemu/blob/5e9d14f2/target/riscv/cpu.h
    */
    uint64_t
    VLMAX(const uint64_t vtype, const bool per_reg = false)
    {
        int64_t lmul = (int64_t)sext<3>(bits(vtype, 2, 0));
        lmul = per_reg ? std::min<int64_t>(0, lmul) : lmul;
        int64_t vsew = bits(vtype, 5, 3);
        return gem5::RiscvISA::VLEN >> (vsew + 3 - lmul);
    }

    uint64_t
    reg_group_nums(const uint64_t vtype)
    {
        int64_t lmul = (int64_t)sext<3>(bits(vtype, 2, 0));
        return 1 << std::max<int64_t>(0, lmul);
    }

    /*
     *  Spec Section 4.5
     *  Ref:
     *  https://github.com/qemu/qemu/blob/c7d773ae/target/riscv/vector_helper.c
    */
    int
    elem_mask(const uint64_t *v0, const int index)
    {
        int idx = index / 64;
        int pos = index % 64;
        return (v0[idx] >> pos) & 1;
    }

    void set_vill(uint64_t& vtype)
    {
        vtype = (uint64_t)0 ^ (1UL << (XLEN-1));
    }

    #define CHECK_VILL                                                      \
    if (bits(tc->readMiscReg(MISCREG_VTYPE), XLEN - 1))                     \
        return std::make_shared<IllegalInstFault>("VILL is set", machInst);

    #define VLOOP(...)                              \
    for (; ei < vl; ei++) {                         \
        size_t i = ei - vlmax_per_reg * greg_idx;   \
        if (i >= vlmax_per_reg) break;              \
        if(vm || elem_mask(v0, i)) __VA_ARGS__      \
    }

    #define ASSIGN_BIT(i, sew, res) \
        ((Vd[i/sew] &= ~(1 << i % sew)) |= ((res) << i % sew))
}};


def template VConfExecute {{
    Fault
    %(class_name)s::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        auto tc = xc->tcBase();
        CHECK_VILL;

        %(op_decl)s;
        %(op_rd)s;
        %(code)s;

        if (vlmax == 0) {
            set_vill(vtype);
            vl = 0;
        }
        tc->setMiscReg(MISCREG_VL, vl);
        tc->setMiscReg(MISCREG_VTYPE, vtype);
        tc->setMiscReg(MISCREG_VSTART, 0);
        %(op_wb)s;
        return NoFault;
    }
}};

def template VIntExecute {{
    Fault
    %(class_name)s::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        auto tc = xc->tcBase();
        CHECK_VILL;

        uint64_t vl = tc->readMiscReg(MISCREG_VL);
        uint64_t vtype = tc->readMiscReg(MISCREG_VTYPE);
        const RiscvISA::vreg_t& tmp_v0 = tc->readVecReg(RegId(VecRegClass, 0));
        auto v0 = tmp_v0.as<uint64_t>();
        auto nums = reg_group_nums(vtype);
        auto vlmax_per_reg = VLMAX(vtype, true);
        size_t greg_idx = 0, ei = 0;

        for (; greg_idx < nums; greg_idx++) {
            if (ei >= vl) break;
            switch (SEW(vtype)) {
                case 8: {
                    using vi [[maybe_unused]] = int8_t;
                    using vu [[maybe_unused]] = uint8_t;
                    %(op_decl)s; %(op_rd)s; %(code)s; %(op_wb)s;
                    break;
                }
                case 16: {
                    using vi [[maybe_unused]] = int16_t;
                    using vu [[maybe_unused]] = uint16_t;
                    %(op_decl)s; %(op_rd)s; %(code)s; %(op_wb)s;
                    break;
                }
                case 32: {
                    using vi [[maybe_unused]] = int32_t;
                    using vu [[maybe_unused]] = uint32_t;
                    %(op_decl)s; %(op_rd)s; %(code)s; %(op_wb)s;
                    break;
                }
                case 64: {
                    using vi [[maybe_unused]] = int64_t;
                    using vu [[maybe_unused]] = uint64_t;
                    %(op_decl)s; %(op_rd)s; %(code)s; %(op_wb)s;
                    break;
                }
                default:
                    panic("Invalid SEW");
            }
        }

        return NoFault;
    }
}};

def template VFloatExecute {{
    Fault
    %(class_name)s::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        auto tc = xc->tcBase();
        CHECK_VILL;

        STATUS status = xc->readMiscReg(MISCREG_STATUS);
        if (status.fs == FPUStatus::OFF)
            return std::make_shared<IllegalInstFault>("VFPU is off", machInst);

        VRM_REQUIRED;

        uint64_t vl = tc->readMiscReg(MISCREG_VL);
        uint64_t vtype = tc->readMiscReg(MISCREG_VTYPE);
        const RiscvISA::vreg_t& tmp_v0 = tc->readVecReg(RegId(VecRegClass, 0));
        auto v0 = tmp_v0.as<uint64_t>();

        auto nums = reg_group_nums(vtype);
        auto vlmax_per_reg = VLMAX(vtype, true);
        size_t greg_idx = 0, ei = 0;

        for (; greg_idx < nums; greg_idx++) {
            if (ei >= vl) break;
            switch (SEW(vtype)) {
                case 32: {
                    using vu = uint32_t;
                    std::function<float32_t(vu)> ftype =
                        [&](vu v){ return f32(v); };
                    std::function<float32_t(float32_t, float32_t)>
                        fadd = f32_add,
                        fsub = f32_sub;
                    std::function<float32_t(float32_t, float32_t, float32_t)>
                        fmadd = f32_mulAdd;

                    %(op_decl)s; %(op_rd)s;

                    RegVal FFLAGS = xc->readMiscReg(MISCREG_FFLAGS);
                    std::feclearexcept(FE_ALL_EXCEPT);

                    %(code)s;

                    FFLAGS |= softfloat_exceptionFlags;
                    softfloat_exceptionFlags = 0;
                    xc->setMiscReg(MISCREG_FFLAGS, FFLAGS);

                    %(op_wb)s;
                    break;
                }
                case 64: {
                    using vu = uint64_t;
                    std::function<float64_t(vu)> ftype =
                        [&](vu v){ return f64(v); };
                    std::function<float64_t(float64_t, float64_t)>
                        fadd = f64_add,
                        fsub = f64_sub;
                    std::function<float64_t(float64_t, float64_t, float64_t)>
                        fmadd = f64_mulAdd;

                    %(op_decl)s; %(op_rd)s;

                    RegVal FFLAGS = xc->readMiscReg(MISCREG_FFLAGS);
                    std::feclearexcept(FE_ALL_EXCEPT);

                    %(code)s;

                    FFLAGS |= softfloat_exceptionFlags;
                    softfloat_exceptionFlags = 0;
                    xc->setMiscReg(MISCREG_FFLAGS, FFLAGS);

                    %(op_wb)s;
                    break;
                }
                default:
                    auto message = "VFPU does not support float" +
                                    std::to_string(SEW(vtype));
                    return std::make_shared<IllegalInstFault>(message,
                        machInst);
            }
        }

        return NoFault;
    }
}};

def template VMvWholeExecute {{
    Fault
    %(class_name)s::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        // TODO: Check register align
        // TODO: If vd is equal to vs2 the instruction is an architectural NOP
        %(op_decl)s; %(op_rd)s;

        %(code)s;

        %(op_wb)s;
        return NoFault;
    }

    std::string
    %(class_name)s::generateDisassembly(
            Addr pc, const loader::SymbolTable *symtab) const
    {
        std::stringstream ss;
        ss << mnemonic << ' ' << registerName(destRegIdx(0)) << ", " <<
            registerName(srcRegIdx(1));
        return ss.str();
    }
}};

def template VMvWholeDeclare {{
    class %(class_name)s : public %(base_class)s
    {
      private:
        %(reg_idx_arr_decl)s;

      public:
        %(class_name)s(MachInst machInst);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        std::string generateDisassembly(
            Addr pc, const loader::SymbolTable *symtab) const override;
    };
}};

def format VIntOp(code, *flags) {{
    iop = InstObjParams(name, Name, 'VArithOp', code, flags)
    header_output = BasicDeclare.subst(iop)
    decoder_output = BasicConstructor.subst(iop)
    decode_block = BasicDecode.subst(iop)
    exec_output = VIntExecute.subst(iop)
}};

def format VFloatOp(code, *flags) {{
    iop = InstObjParams(name, Name, 'VArithOp', code, flags)
    header_output = BasicDeclare.subst(iop)
    decoder_output = BasicConstructor.subst(iop)
    decode_block = BasicDecode.subst(iop)
    exec_output = VFloatExecute.subst(iop)
}};

def format VMvWholeOp(code, *flags) {{
    iop = InstObjParams(name, Name, 'VArithOp', code, flags)
    header_output = VMvWholeDeclare.subst(iop)
    decoder_output = BasicConstructor.subst(iop)
    decode_block = BasicDecode.subst(iop)
    exec_output = VMvWholeExecute.subst(iop)
}};

def format VConfOp(code, *flags) {{
    iop = InstObjParams(name, Name, 'VConfOp', code, flags)
    header_output = BasicDeclare.subst(iop)
    decoder_output = BasicConstructor.subst(iop)
    decode_block = BasicDecode.subst(iop)
    exec_output = VConfExecute.subst(iop)
}};

////////////////////////////////////////////////////////////////////
//
// Vector memory operation instructions
//
def template VMemLoadStoreOpDeclare {{
    /**
     * Static instruction class for "%(mnemonic)s".
     */
    class %(class_name)s : public %(base_class)s
    {
      private:
        %(reg_idx_arr_decl)s;

      public:
        /// Constructor.
        %(class_name)s(ExtMachInst machInst);

        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
        Fault completeAcc(PacketPtr, ExecContext *,
                          Trace::InstRecord *) const override;
    };
}};

def template VMemLoadStoreOpConstructor {{
    %(class_name)s::%(class_name)s(ExtMachInst machInst):
        %(base_class)s("%(mnemonic)s", machInst, %(op_class)s,
        (MEW<<3)|WIDTH, VM)
    {
        %(set_reg_idx_arr)s;
        %(constructor)s;
    }
}};

let {{
    def VMemLoadStoreOpBase(name, Name, memacc_code, ea_code,
            mem_flags, inst_flags, base_class,
            decode_template=BasicDecode, exec_template_base=''):
        # Make sure flags are in lists (convert to lists if not).
        mem_flags = makeList(mem_flags)
        inst_flags = makeList(inst_flags)

        iop = InstObjParams(name, Name, base_class,
            {'ea_code': ea_code, 'memacc_code': memacc_code },
            inst_flags)

        if mem_flags:
            mem_flags = [ 'Request::%s' % flag for flag in mem_flags ]
            s = '\n\tthis->memAccessFlags = ' + '|'.join(mem_flags) + ';'
            iop.constructor += s

        # select templates
        fullExecTemplate = eval(exec_template_base + 'Execute')
        initiateAccTemplate = eval(exec_template_base + 'InitiateAcc')
        completeAccTemplate = eval(exec_template_base + 'CompleteAcc')

        # (header_output, decoder_output, decode_block, exec_output)
        return (VMemLoadStoreOpDeclare.subst(iop),
            VMemLoadStoreOpConstructor.subst(iop),
            decode_template.subst(iop),
            fullExecTemplate.subst(iop) +
            initiateAccTemplate.subst(iop) +
            completeAccTemplate.subst(iop))
}};

def template VMemLoadExecute {{
    Fault %(class_name)s::execute(
        ExecContext *xc, Trace::InstRecord *traceData) const
    {
        auto tc = xc->tcBase();
        CHECK_VILL;

        Addr EA;
        Fault fault = NoFault;

        size_t vl = tc->readMiscReg(MISCREG_VL);
        uint64_t vtype = tc->readMiscReg(MISCREG_VTYPE);
        STATUS status = xc->readMiscReg(MISCREG_STATUS);
        if (status.vs == static_cast<int>(VPUStatus::OFF))
            fault = std::make_shared<IllegalInstFault>("VPU is off", machInst);

        if (fault != NoFault) return fault;

        const RiscvISA::vreg_t& tmp_v0 = tc->readVecReg(RegId(VecRegClass, 0));
        auto v0 = tmp_v0.as<uint64_t>();

        auto nums = reg_group_nums(vtype);
        auto vlmax_per_reg = VLMAX(vtype, true);
        size_t greg_idx = 0, ei = 0;
        for (; greg_idx < nums; greg_idx++) {
            if (ei >= vl) break;
            %(op_decl)s; %(op_rd)s; %(ea_code)s;

            auto offset = vlmax_per_reg * this->sew * greg_idx;
            auto bytes_to_read = std::min(vlmax_per_reg * this->sew,
                                          vl * this->sew - offset);
            const std::vector<bool> byte_enable(bytes_to_read, true);
            fault = readMemAtomic(xc, EA + offset, Mem.as<uint8_t>(),
                bytes_to_read, this->memAccessFlags, byte_enable);

            if (fault != NoFault) return fault;

            VLOOP({ %(memacc_code)s; });
            %(op_wb)s;
        }

        return fault;
    }
}};

def template VMemLoadInitiateAcc {{
    Fault %(class_name)s::initiateAcc(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        auto tc = xc->tcBase();
        CHECK_VILL;

        Addr EA;
        Fault fault = NoFault;

        %(op_src_decl)s;
        %(op_rd)s;
        %(ea_code)s;

        return initiateMemRead(xc, traceData, EA, Mem,
            this->memAccessFlags);
    }
}};

def template VMemLoadCompleteAcc {{
    Fault %(class_name)s::completeAcc(PacketPtr pkt, ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        auto tc = xc->tcBase();
        size_t vl = tc->readMiscReg(MISCREG_VL);
        uint64_t vtype = tc->readMiscReg(MISCREG_VTYPE);

        STATUS status = xc->readMiscReg(MISCREG_STATUS);
        if (status.vs == static_cast<int>(VPUStatus::OFF))
            fault = std::make_shared<IllegalInstFault>("VPU is off", machInst);

        if (fault != NoFault) return fault;

        const RiscvISA::vreg_t& tmp_v0 =
            tc->readVecReg(RegId(VecRegClass, 0));
        auto v0 = tmp_v0.as<uint64_t>();

        auto nums = reg_group_nums(vtype);
        auto vlmax_per_reg = VLMAX(vtype, true);
        size_t greg_idx = 0, ei = 0;
        for (; greg_idx < nums; greg_idx++) {
            if (ei >= vl) break;
            %(op_decl)s; %(op_rd)s;

            auto offset = vlmax_per_reg * this->sew * greg_idx;
            auto bytes_to_read = std::min(vlmax_per_reg * this->sew,
                                          vl * this->sew - offset);
            memcpy(Mem.as<uint8_t>(), pkt->getPtr<uint8_t>() + offset,
                   bytes_to_read);
            VLOOP({ %(memacc_code)s; });
            %(op_wb)s;
        }

        return fault;
    }
}};

def template VMemStoreExecute {{
    Fault %(class_name)s::execute(
        ExecContext *xc, Trace::InstRecord *traceData) const
    {
        auto tc = xc->tcBase();
        CHECK_VILL;

        Addr EA;
        Fault fault = NoFault;

        size_t vl = tc->readMiscReg(MISCREG_VL);
        uint64_t vtype = tc->readMiscReg(MISCREG_VTYPE);

        if (fault != NoFault) return fault;

        const RiscvISA::vreg_t& tmp_v0 =
            tc->readVecReg(RegId(VecRegClass, 0));
        auto v0 = tmp_v0.as<uint64_t>();
        auto nums = reg_group_nums(vtype);
        auto vlmax_per_reg = VLMAX(vtype, true);
        size_t greg_idx = 0, ei = 0;
        for (; greg_idx < nums; greg_idx++) {
            if (ei >= vl) break;
            %(op_decl)s; %(op_rd)s; %(ea_code)s;

            auto offset = vlmax_per_reg * this->sew * greg_idx;
            auto bytes_to_read = std::min(vlmax_per_reg * this->sew,
                                          vl * this->sew - offset);
            const std::vector<bool> byte_enable(bytes_to_read, true);
            fault = readMemAtomic(xc, EA + offset, Mem.as<uint8_t>(),
                bytes_to_read, this->memAccessFlags, byte_enable);

            if (fault != NoFault) return fault;

            VLOOP({ %(memacc_code)s; });
            %(op_wb)s;

            fault = writeMemAtomic(xc, Mem.as<uint8_t>(), EA + offset,
                bytes_to_read, this->memAccessFlags, nullptr, byte_enable);

            if (fault != NoFault) return fault;
        }

        return fault;
    }
}};

def template VMemStoreInitiateAcc {{
    Fault %(class_name)s::initiateAcc(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        auto tc = xc->tcBase();
        CHECK_VILL;

        Addr EA;
        Fault fault = NoFault;

        STATUS status = xc->readMiscReg(MISCREG_STATUS);
        size_t vl = tc->readMiscReg(MISCREG_VL);
        uint64_t vtype = tc->readMiscReg(MISCREG_VTYPE);

        if (status.vs == static_cast<int>(VPUStatus::OFF))
            fault = std::make_shared<IllegalInstFault>("VPU is off", machInst);

        if (fault != NoFault) return fault;

        const RiscvISA::vreg_t& tmp_v0 = tc->readVecReg(RegId(VecRegClass, 0));
        auto v0 = tmp_v0.as<uint64_t>();

        auto nums = reg_group_nums(vtype);
        auto vlmax_per_reg = VLMAX(vtype, true);
        size_t greg_idx = 0, ei = 0;
        for (; greg_idx < nums; greg_idx++) {
            if (ei >= vl) break;
            %(op_src_decl)s; %(op_rd)s; %(ea_code)s;

            auto offset = vlmax_per_reg * this->sew * greg_idx;
            auto bytes_to_read = std::min(vlmax_per_reg * this->sew,
                                          vl * this->sew - offset);
            const std::vector<bool> byte_enable(bytes_to_read, true);
            fault = readMemAtomic(xc, EA + offset, Mem.as<uint8_t>(),
                bytes_to_read, this->memAccessFlags, byte_enable);

            if (fault != NoFault) return fault;

            VLOOP({ %(memacc_code)s; });
            %(op_wb)s;

            fault = writeMemAtomic(xc, Mem.as<uint8_t>(), EA + offset,
                bytes_to_read, this->memAccessFlags, nullptr, byte_enable);

            if (fault != NoFault) return fault;
        }

        return fault;
    }
}};

def template VMemStoreCompleteAcc {{
    Fault %(class_name)s::completeAcc(PacketPtr pkt, ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        return NoFault;
    }
}};

def format VMemLoadOp (
    memacc_code, ea_code={{EA = Rs1}},
    mem_flags=[], inst_flags=[]
) {{
    (header_output, decoder_output, decode_block, exec_output) = \
        VMemLoadStoreOpBase(name, Name, memacc_code, ea_code,
        mem_flags, inst_flags, 'VMemLoadOp', exec_template_base='VMemLoad')
}};

def format VMemStoreOp (
    memacc_code, ea_code={{EA = Rs1}},
    mem_flags=[], inst_flags=[]
) {{
    (header_output, decoder_output, decode_block, exec_output) = \
        VMemLoadStoreOpBase(name, Name, memacc_code, ea_code,
        mem_flags, inst_flags, 'VMemStoreOp',
        exec_template_base='VMemStore')
}};